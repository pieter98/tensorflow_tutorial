{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_Tensorflow_Tutorial.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOR61oKzd1CHlJKdiI7af6v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pieter98/tensorflow_tutorial/blob/main/Classification_Tensorflow_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTg5JFZvK3XW"
      },
      "source": [
        "#Setup\n",
        "basic installation of sklearn for the google colab notebook, and all necessary imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QuRisfHCNqK"
      },
      "source": [
        "!pip install -q sklearn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-xklNUhCTPU",
        "outputId": "aeb92ccf-eb17-4cc8-d1da-d8e146c67ace"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "\n",
        "import tensorflow.compat.v2.feature_column as fc\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTFWf1cdCeQT"
      },
      "source": [
        "#Dataset\n",
        "using the flower dataset, load using keras and pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH9a0Mo9Cn7k"
      },
      "source": [
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVU-58FkDOQG",
        "outputId": "ebb0317a-dc8c-47d8-c6d7-e287a09dc1de"
      },
      "source": [
        "train_path = tf.keras.utils.get_file(\n",
        "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "test_path = tf.keras.utils.get_file(\n",
        "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
        "\n",
        "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "# Here we use keras (a module inside of TensorFlow) to grab our datasets and read them into a pandas dataframe"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
            "\r8192/2194 [================================================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
            "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "e50tInBADkmb",
        "outputId": "00c87680-56f0-40e3-cbdb-cfb36c5a3d42"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLength</th>\n",
              "      <th>SepalWidth</th>\n",
              "      <th>PetalLength</th>\n",
              "      <th>PetalWidth</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
              "0          6.4         2.8          5.6         2.2        2\n",
              "1          5.0         2.3          3.3         1.0        1\n",
              "2          4.9         2.5          4.5         1.7        2\n",
              "3          4.9         3.1          1.5         0.1        0\n",
              "4          5.7         3.8          1.7         0.3        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrxFncHoLZ4R"
      },
      "source": [
        "pop labels from both the training and the evaluation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "NbVIM31sDxUm",
        "outputId": "adcedccc-4f78-4f56-f7bc-e9b148504312"
      },
      "source": [
        "train_y = train.pop('Species')\n",
        "test_y = test.pop('Species')\n",
        "train.head() # the species column is now gone"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLength</th>\n",
              "      <th>SepalWidth</th>\n",
              "      <th>PetalLength</th>\n",
              "      <th>PetalWidth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
              "0          6.4         2.8          5.6         2.2\n",
              "1          5.0         2.3          3.3         1.0\n",
              "2          4.9         2.5          4.5         1.7\n",
              "3          4.9         3.1          1.5         0.1\n",
              "4          5.7         3.8          1.7         0.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9objLEbEPZ3"
      },
      "source": [
        "#Input function\n",
        "creating an input function\n",
        "\n",
        "**note**: no nested input function like we've seen in the linear regression tutorial, we'll use a lambda function to circumvent this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BicP6ty2EScj"
      },
      "source": [
        "# single function definition, we'll use a lambda function later on instead of a nested function\n",
        "def input_fn(features, labels, training=True, batch_size=256):\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "    # Shuffle and repeat if you are in training mode.\n",
        "    if training:\n",
        "        dataset = dataset.shuffle(1000).repeat()\n",
        "    \n",
        "    return dataset.batch(batch_size)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e49ggP_WEqB0"
      },
      "source": [
        "#Feature columns\n",
        "creating the feature columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQPkdxMzEog4",
        "outputId": "f307fba2-d4a1-4bcb-a634-cdca0756c534"
      },
      "source": [
        "my_feature_columns = []\n",
        "for key in train.keys():\n",
        "  my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "print(my_feature_columns)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNx5CwjdE9oe"
      },
      "source": [
        "#Classifier model\n",
        "creating the classifier model using one of tensorflows pre-defined models (accessible using tf.estimator)\n",
        "\n",
        "- pass on the discovered features to the classifier\n",
        "- we use 2 hidden layers with the first having 30 hidden nodes and the second having 10. \n",
        "- The amount of classes is 3 (corresponding to the three flower species we have data for 'Setosa', 'Versicolor', 'Virginica')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vK6rffMfFACJ",
        "outputId": "f8e1f043-3e75-4952-ccb7-4574dabf60bb"
      },
      "source": [
        "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns=my_feature_columns,\n",
        "    # Two hidden layers of 30 and 10 nodes respectively.\n",
        "    hidden_units=[30, 10],\n",
        "    # The model must choose between 3 classes.\n",
        "    n_classes=3)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpc8yu9ebe\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpc8yu9ebe', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSsCbYRMF4xe"
      },
      "source": [
        "#Training the classifier model\n",
        "to get the input function we use a lambda function that returns our defined input function with the necessary parameters which are:\n",
        "- train dataset as feature set\n",
        "- train_y dataset as labels\n",
        "- training=True to shuffle the given data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwpA2ZSKF6pa"
      },
      "source": [
        "# steps is similar to epochs, it indicates x datapoints to be looked at untill training is done\n",
        "classifier.train(\n",
        "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
        "    steps=5000\n",
        ")\n",
        "clear_output()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMb2r1P5GpKs"
      },
      "source": [
        "#Evaluating the model\n",
        "after we've trained the model we can evaluate it's accuracy by using the evaluation dataset (test) and it's corresponding labels (test_y) as input\n",
        "\n",
        "we print the accuracy from the eval_result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRh97mCtGowm",
        "outputId": "fc89d186-35a2-410e-ffdb-e9ba8e3331b4"
      },
      "source": [
        "eval_result = classifier.evaluate(\n",
        "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
        "clear_output()\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set accuracy: 0.967\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rulQQ_q5HMqb"
      },
      "source": [
        "#Predictions\n",
        "with an accuracy of 96.7% we can consider our model to be fairly accurate, therefor we can use it to make predictions based on a set of given features\n",
        "\n",
        "1) create an input function that just accepts a set of features en returns them as a tensorflow Dataset\n",
        "\n",
        "2) we use a simple input loop to get values for all required features ('SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth'), we save these values in a dictionary per featurename\n",
        "\n",
        "3) we use the classifier model to predict the flower class of the given data and display the class id and the prediction probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwebLROOHSSU",
        "outputId": "0336ef9f-af1c-4c4c-ec63-f0d33bda4918"
      },
      "source": [
        "def input_fn(features, batch_size=256):\n",
        "  return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "\n",
        "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
        "predict = {}\n",
        "\n",
        "print(\"Please type numeric values as prompted.\")\n",
        "for feature in features:\n",
        "  valid = True\n",
        "  while valid: \n",
        "    val = input(feature + \": \")\n",
        "    if not val.isdigit(): valid = False\n",
        "\n",
        "  predict[feature] = [float(val)]\n",
        "\n",
        "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
        "clear_output()\n",
        "for pred_dict in predictions:\n",
        "    class_id = pred_dict['class_ids'][0]\n",
        "    probability = pred_dict['probabilities'][class_id]\n",
        "\n",
        "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
        "        SPECIES[class_id], 100 * probability))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpc8yu9ebe/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Prediction is \"Setosa\" (91.3%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Pds3Ee3PD29"
      },
      "source": [
        "#Illustration using known values\n",
        "Here we have 3 cases where we know the flower class and we have the corresponding measurements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxzZWAoRQHNn"
      },
      "source": [
        "Setosa with:\n",
        "- sepalLength: 5.1\n",
        "- sepalWidth: 3.3\n",
        "- petalLength: 1.7\n",
        "- petalWidth: 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qo6q-n2P-zK",
        "outputId": "dff7807d-2b03-48e1-9dbd-358bb6956568"
      },
      "source": [
        "flower_data = {'SepalLength': [5.1], 'SepalWidth': [3.3], 'PetalLength': [1.7], 'PetalWidth': [0.5]}\n",
        "\n",
        "predictions = classifier.predict(input_fn=lambda: input_fn(flower_data))\n",
        "clear_output()\n",
        "for pred_dict in predictions:\n",
        "    class_id = pred_dict['class_ids'][0]\n",
        "    probability = pred_dict['probabilities'][class_id]\n",
        "\n",
        "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
        "        SPECIES[class_id], 100 * probability))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpc8yu9ebe/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Prediction is \"Setosa\" (91.3%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWK5O-HURiGt"
      },
      "source": [
        "Versicolor with:\n",
        "- sepalLength: 5.9\n",
        "- sepalWidth: 3.0\n",
        "- petalLength: 4.2\n",
        "- petalWidth: 1.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMwQPNd2RuV1",
        "outputId": "5f1803e3-36e2-4124-d3f7-dc4e17676800"
      },
      "source": [
        "flower_data = {'SepalLength': [5.9], 'SepalWidth': [3.0], 'PetalLength': [4.2], 'PetalWidth': [1.5]}\n",
        "\n",
        "predictions = classifier.predict(input_fn=lambda: input_fn(flower_data))\n",
        "clear_output()\n",
        "for pred_dict in predictions:\n",
        "    class_id = pred_dict['class_ids'][0]\n",
        "    probability = pred_dict['probabilities'][class_id]\n",
        "\n",
        "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
        "        SPECIES[class_id], 100 * probability))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpc8yu9ebe/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Prediction is \"Versicolor\" (63.1%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBOizmMbR5Mu"
      },
      "source": [
        "Virginica with:\n",
        "- sepalLength: 6.9\n",
        "- sepalWidth: 3.1\n",
        "- petalLength: 5.4\n",
        "- petalWidth: 2.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xgkD5JWSDX9",
        "outputId": "c19764f9-764c-4094-d0ab-9dbd7f0c89b6"
      },
      "source": [
        "flower_data = {'SepalLength': [6.9], 'SepalWidth': [3.1], 'PetalLength': [5.4], 'PetalWidth': [2.1]}\n",
        "\n",
        "predictions = classifier.predict(input_fn=lambda: input_fn(flower_data))\n",
        "clear_output()\n",
        "for pred_dict in predictions:\n",
        "    class_id = pred_dict['class_ids'][0]\n",
        "    probability = pred_dict['probabilities'][class_id]\n",
        "\n",
        "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
        "        SPECIES[class_id], 100 * probability))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpc8yu9ebe/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Prediction is \"Virginica\" (69.2%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}